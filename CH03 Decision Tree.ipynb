{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CH3 Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introductions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://en.wikipedia.org/wiki/ID3_algorithm\n",
    "- 决策树学习通常包含三个步骤: 特征选择，决策树生成，决策树修剪[Lihang P55]\n",
    "- 决策树模型\n",
    "    - if-then规则\n",
    "    - 条件概率分布\n",
    "\n",
    "信息定义 $$l(x_i)=-log_2p(x_i)$$\n",
    "熵定义 $$H=-\\sum_{i=1}^{n}p(x_i)log_2p(x_i)$$\n",
    "决策树学习的损失函数通常是正则化的极大似然函数。\n",
    "\n",
    "决策树的学习策略是以损失函数为目标函数的最小化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Map Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts import TreeMap\n",
    "\n",
    "data = [\n",
    "    {\n",
    "        \"value\": 50,\n",
    "        \"name\": \"发送邮件域名地址为:🔗🔗🔗🔗:是->无聊时需要阅读\",\n",
    "    },\n",
    "    {\n",
    "        \"value\": 50,\n",
    "        \"name\": \"发送邮件域名地址为:🔗🔗🔗🔗:否\",\n",
    "        \"children\": [\n",
    "            {\"value\": 50,\n",
    "             \"name\": \"是否包含单词曲棍球:是->需要及时处理的朋友邮件\",\n",
    "             },\n",
    "            {\n",
    "                \"value\": 50,\n",
    "                \"name\": \"是否包含单词曲棍球:否->垃圾邮件\",\n",
    "            },\n",
    "\n",
    "        ]\n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "treemap = TreeMap(\"决策树\",\"可以通过下钻的方式展示决策的过程，例子参考MLiA中图3-1\", width=800, height=500)\n",
    "treemap.use_theme(\"dark\")\n",
    "treemap.add(\"发送邮件域名地址为:🔗🔗🔗🔗\", data, is_label_show=True, label_pos='inside', treemap_left_depth=1)\n",
    "treemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLiA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = pd.DataFrame({'no surfacing':[1,1,1,0,0],'flippers':[1,1,0,1,1],'is Fish':['yes','yes','no','no','no']},columns=[\"no surfacing\",\"flippers\",\"is Fish\"])\n",
    "dataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcShannonEnt(dataSet):\n",
    "    col = dataSet.columns.tolist()[-1]\n",
    "    prob = dataSet.groupby(by=col).size()/len(dataSet)\n",
    "    return sum(-np.log2(prob)*prob)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcShannonEnt(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet[\"is Fish\"].iloc[0] = \"maybe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcShannonEnt(dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conditional Entroy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "书里少解释了一个点，条件熵(conditional entropy)\n",
    "\n",
    "$$ H(Y|X)=\\sum_{i=1}^{n}p_iH(Y|X=x_i)$$\n",
    "\n",
    "其中$p_i=P(X=x_i),i=1,2,...,n$\n",
    "\n",
    "[李航，2012，P61]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitDataSet(dataSet,axis,value):\n",
    "    return dataSet[dataSet[axis] == value][dataSet.columns.drop(axis)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitDataSet(dataSet,\"flippers\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcShannonEnt(splitDataSet(dataSet,\"no surfacing\",0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcShannonEnt(splitDataSet(dataSet,\"no surfacing\",1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcShannonEnt(splitDataSet(dataSet,\"flippers\",0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcShannonEnt(splitDataSet(dataSet,\"flippers\",1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    feas = dataSet.columns.tolist()[:-1]\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    bestInfoGain = 0\n",
    "    \n",
    "    for fea in feas:\n",
    "        newEntropy = 0\n",
    "        for value in set(dataSet[fea]):\n",
    "            subSet = splitDataSet(dataSet,fea,value)\n",
    "            #conditional entropy\n",
    "            Pi = len(subSet)/len(dataSet)\n",
    "            newEntropy += Pi*calcShannonEnt(subSet)\n",
    "    \n",
    "        infoGain = baseEntropy - newEntropy\n",
    "        if  (infoGain > bestInfoGain):\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = fea\n",
    "    return bestFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcShannonEnt(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas = dataSet.columns.tolist()[:-1]\n",
    "feas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(dataSet[\"flippers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chooseBestFeatureToSplit(dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "def majorityCnt(dataSet):\n",
    "    label = dataSet.columns.tolist()[-1]\n",
    "    return sorted(dataSet.groupby(by=label).size().iteritems(),key=operator.itemgetter(1),reverse=True)[0][0]\n",
    "majorityCnt(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteritems\n",
    "list(dataSet.groupby(by=\"is Fish\").size().iteritems())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createTree(dataSet):\n",
    "#     print(\"======\")\n",
    "#     print(dataSet)\n",
    "    # stop condition\n",
    "    feas = dataSet.columns.tolist()[:-1]\n",
    "    label = dataSet[dataSet.columns.tolist()[-1]]\n",
    "    # 参考下李航 CH5 里面算法的描述\n",
    "    # entropy == 0\n",
    "    if len(set(label)) == 1:\n",
    "#         print(\"condition 1\")\n",
    "        return list(label)[0]\n",
    "    # 参考下李航CH5里面的算法描述\n",
    "    # no feature to use\n",
    "    if len(set(feas)) == 0:\n",
    "#         print(\"condition 2\")\n",
    "        return majorityCnt(dataSet)\n",
    "    bestFeature = chooseBestFeatureToSplit(dataSet)\n",
    "    myTree = {bestFeature:{}}\n",
    "    featValues = set(dataSet[bestFeature])\n",
    "#     print(featValues)\n",
    "    for value in featValues:\n",
    "        subDataSet = dataSet[dataSet[bestFeature]==value]\n",
    "        myTree[bestFeature][value] = createTree(splitDataSet(subDataSet,bestFeature,value))\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTree = createTree(dataSet)\n",
    "myTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionNode = dict(boxstyle=\"sawtooth\",fc=\"0.8\")\n",
    "leafNode = dict(boxstyle=\"round4\",fc=\"0.8\")\n",
    "arrow_args= dict(arrowstyle=\"<-\")\n",
    "def plotNode(nodeTxt, centerPt, parentPt, nodeType):\n",
    "    createPlot.ax1.annotate(nodeTxt,rotation = 90,\n",
    "                            xy=parentPt,xycoords=\"axes fraction\",\n",
    "                            xytext=centerPt,textcoords=\"axes fraction\",\n",
    "                            va=\"center\",ha=\"center\",bbox=nodeType,arrowprops=arrow_args)\n",
    "def createPlot():\n",
    "    fig = plt.figure(1, facecolor=\"white\")\n",
    "    fig.clf()\n",
    "    createPlot.ax1 = plt.subplot(111,frameon=False)\n",
    "    plotNode('a decision node',(0.5,0.1),(0.1,0.5),decisionNode)\n",
    "    plotNode('a leaf node',(0.8,0.1),(0.3,0.8),leafNode)\n",
    "    plt.show()\n",
    "createPlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTree.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTree.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet[dataSet[\"is Fish\"] == \"maybe\"].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTree.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"no surfacing\",\"flippers\"]\n",
    "labels.index(\"flippers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(myTree.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"flippers\" in myTree.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkNode(nodeIn):\n",
    "    keys = list(nodeIn.keys())\n",
    "    for key in keys:\n",
    "        childNode = nodeIn[key]\n",
    "        print(\"key\",key)\n",
    "        if type(childNode).__name__ == 'dict':\n",
    "            checkNode(childNode)\n",
    "        else:\n",
    "            print(\"leaf:\",childNode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkNode(myTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(myTree.keys())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNumLeafs(myTree):\n",
    "    numLeafs = 0\n",
    "    firstStr = list(myTree.keys())[0]\n",
    "    secondDict = myTree[firstStr]\n",
    "    for key in secondDict.keys():\n",
    "        if type(secondDict[key]).__name__ == \"dict\":\n",
    "            numLeafs += getNumLeafs(secondDict[key])\n",
    "        else:\n",
    "            numLeafs += 1\n",
    "    return numLeafs\n",
    "\n",
    "def getTreeDepth(myTree):\n",
    "    maxDepth = 0\n",
    "    firstStr = list(myTree.keys())[0]\n",
    "    secondDict = myTree[firstStr]\n",
    "    for key in secondDict.keys():\n",
    "        if type(secondDict[key]).__name__==\"dict\":\n",
    "            thisDepth = 1 + getTreeDepth(secondDict[key])\n",
    "        else:\n",
    "            thisDepth = 1\n",
    "        if thisDepth > maxDepth: maxDepth = thisDepth\n",
    "    return maxDepth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotMidText(cntrPt, parentPt, txtString):\n",
    "    xMid = (parentPt[0]-cntrPt[0])/2.0 + cntrPt[0]\n",
    "    yMid = (parentPt[1]-cntrPt[1])/2.0 + cntrPt[1]\n",
    "    createPlot.ax1.text(xMid,yMid,txtString)\n",
    "# 参数命名尽量不要和全局的重合，不方便debug\n",
    "def plotTree(myTree, parentPt, nodeTxt):\n",
    "    numLeafs = getNumLeafs(myTree)\n",
    "    depth = getTreeDepth(myTree)\n",
    "#     print(\"dict\",myTree)\n",
    "    firstStr = list(myTree.keys())[0]\n",
    "    cntrPt = (plotTree.xOff + (1.0 + float(numLeafs))/2.0/plotTree.totalW, plotTree.yOff)\n",
    "    plotMidText(cntrPt, parentPt, nodeTxt)\n",
    "    plotNode(firstStr,cntrPt,parentPt,decisionNode)\n",
    "    secondDict = myTree[firstStr]\n",
    "    plotTree.yOff = plotTree.yOff - 1.0/plotTree.totalD\n",
    "#     print(\"second\",secondDict)\n",
    "    for key in secondDict.keys():\n",
    "        if type(secondDict[key]).__name__ == 'dict':\n",
    "#             print(\"key\",key,\"dict\",secondDict[key])\n",
    "            plotTree(secondDict[key],cntrPt,str(key))\n",
    "        else:\n",
    "            plotTree.xOff = plotTree.xOff + 1.0/plotTree.totalW\n",
    "            plotNode(secondDict[key],(plotTree.xOff,plotTree.yOff),cntrPt,leafNode)\n",
    "            plotMidText((plotTree.xOff,plotTree.yOff),cntrPt,str(key))\n",
    "    plotTree.yOff = plotTree.yOff + 1.0/plotTree.totalD\n",
    "\n",
    "def createPlot(inTree):\n",
    "    fig = plt.figure(1,facecolor='white')\n",
    "    fig.clf()\n",
    "    axprops = dict(xticks=[],yticks=[])\n",
    "    createPlot.ax1 = plt.subplot(111,frameon=False, **axprops)\n",
    "    plotTree.totalW = float(getNumLeafs(inTree))\n",
    "    plotTree.totalD = float(getTreeDepth(inTree))\n",
    "    plotTree.xOff = -0.5/plotTree.totalW\n",
    "    plotTree.yOff = 1.0\n",
    "    plotTree(inTree,(0.5,1.0),'')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createPlot(myTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tmpfun():\n",
    "    return tmpfun.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpfun.test = 1\n",
    "tmpfun()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(inputTree, featLabels,testVec):\n",
    "    firstStr = list(inputTree.keys())[0]\n",
    "    secondDict = inputTree[firstStr]\n",
    "    featIndex = featLabels.index(firstStr)\n",
    "    for key in secondDict.keys():\n",
    "        if testVec[featIndex] == key:\n",
    "            if type(secondDict[key]).__name__ == \"dict\":\n",
    "                classLabel = classify(secondDict[key],featLabels,testVec)\n",
    "            else:\n",
    "                classLabel = secondDict[key]\n",
    "    return classLabel       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(inputTree=myTree,featLabels=[\"no surfacing\",\"flippers\"],testVec=[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def storeTree(inputTree,filename):\n",
    "    import pickle\n",
    "    with open(filename,'wb') as f:\n",
    "        pickle.dump(inputTree,f)\n",
    "def grabTree(filename):\n",
    "    import pickle\n",
    "    with open(filename,'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lenses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lenseData = pd.read_csv(\"./Data/CH3/lenses/lenses.data\",\n",
    "                index_col=0,\n",
    "                names=[\"idx\",\"age of the patient\",\"spectacle prescription\",\"astigmatic\",\"tear production rate\",\"type\"],\n",
    "                sep = \"\\s+\")\n",
    "# note this sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenseData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenseTree = createTree(lenseData)\n",
    "lenseTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createPlot(lenseTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts import TreeMap\n",
    "\n",
    "data = [\n",
    "    {\n",
    "        \"value\": 50,\n",
    "        \"name\": \"reduced->no lenses\",\n",
    "    },\n",
    "    {\n",
    "        \"value\": 50,\n",
    "        \"name\": \"normal->astigmatic\",\n",
    "        \"children\": [\n",
    "            {\"value\": 50,\n",
    "             \"name\": \"yes->prescript\",\n",
    "             \"children\":[\n",
    "                 {\"value\":50,\n",
    "                  \"name\": \"hyper->age\",\n",
    "                  \"children\":[\n",
    "                      {\"value\":30,\n",
    "                      \"name\":\"pre->nolenses\"},\n",
    "                      {\"value\":30,\n",
    "                      \"name\":\"presbyopic->nolenses\"},\n",
    "                      {\"value\":30,\n",
    "                      \"name\":\"young->hard\"}\n",
    "                  ]\n",
    "                  },\n",
    "                 {\n",
    "                     \"value\":50,\n",
    "                     \"name\": \"myope->hard\",\n",
    "                 },\n",
    "             ]\n",
    "             },\n",
    "            {\n",
    "                \"value\": 50,\n",
    "                \"name\": \"no->age\",\n",
    "                \"children\":[\n",
    "                          {\"value\":30,\n",
    "                           \"name\":\"pre->soft\"},\n",
    "                          {\"value\":30,\n",
    "                           \"name\":\"presbyopic->prescript\",\n",
    "                       \"children\":[\n",
    "                                  {\"value\":50,\n",
    "                                  \"name\":\"hyper->soft\"},\n",
    "                                  {\"value\":50,\n",
    "                                  \"name\":\"myope->no lenses\"},\n",
    "                       ]\n",
    "                      },\n",
    "                      {\"value\":30,\n",
    "                       \"name\":\"young->soft\"}\n",
    "                ]\n",
    "            },\n",
    "\n",
    "        ]\n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "treemap = TreeMap(\"隐形眼镜分类决策树\",\"\", width=800, height=500)\n",
    "treemap.use_theme(\"dark\")\n",
    "treemap.add(\"tearRate\", data, is_label_show=True, label_pos='inside')\n",
    "treemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = pd.DataFrame({'no surfacing':[1,1,1,0,0],'flippers':[1,1,0,1,1],'is Fish':['yes','yes','no','no','no']},columns=[\"no surfacing\",\"flippers\",\"is Fish\"])\n",
    "dataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_fish = DecisionTreeClassifier(criterion=\"entropy\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataSet.values[:,:-1]\n",
    "y = dataSet.values[:,-1]\n",
    "dt_fish.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz \n",
    "dot_data = export_graphviz(dt_fish,out_file=None,\n",
    "                           feature_names=dataSet.columns.tolist()[:-1],\n",
    "                           class_names=[\"no\",\"yes\"],\n",
    "                           filled=True,\n",
    "                           rounded=True,  \n",
    "                           special_characters=True) \n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上\n",
    "- 和图3-2是一样的，0.5划分0，1，因为恰巧这个例子是二分类，还是0，1\n",
    "- 书中是按照ID3，sklearn按照CART,参考[相关文档](http://scikit-learn.org/stable/modules/tree.html#tree-algorithms)\n",
    "- 这个例子gini和entropy没区别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lenses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenseData = pd.read_csv(\"./Data/CH3/lenses/lenses.data\",\n",
    "                index_col=0,\n",
    "                names=[\"idx\",\"age of the patient\",\"spectacle prescription\",\"astigmatic\",\"tear production rate\",\"type\"],\n",
    "                sep = \"\\s+\")\n",
    "lenseData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenseData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = lenseData.values[:,:-1]\n",
    "y = lenseData.values[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_lenses = DecisionTreeClassifier(criterion=\"gini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_lenses.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(dt_lenses,out_file=None,\n",
    "                           feature_names=lenseData.columns.tolist()[:-1],\n",
    "                           class_names=[\"hard\",\"soft\",\"no lenses\"],\n",
    "                           filled=True,\n",
    "                           rounded=True,  \n",
    "                           special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上\n",
    "- Sklearn实现了优化的CART，是二叉树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are all the various decision tree algorithms and how do they differ from each other? Which one is implemented in scikit-learn?\n",
    "\n",
    "ID3 (Iterative Dichotomiser 3) was developed in 1986 by Ross Quinlan. The algorithm creates a multiway tree, finding for each node (i.e. in a greedy manner) the categorical feature that will yield the largest information gain for categorical targets. Trees are grown to their maximum size and then a pruning step is usually applied to improve the ability of the tree to generalise to unseen data.\n",
    "\n",
    "C4.5 is the successor to ID3 and removed the restriction that features must be categorical by dynamically defining a discrete attribute (based on numerical variables) that partitions the continuous attribute value into a discrete set of intervals. C4.5 converts the trained trees (i.e. the output of the ID3 algorithm) into sets of if-then rules. These accuracy of each rule is then evaluated to determine the order in which they should be applied. Pruning is done by removing a rule’s precondition if the accuracy of the rule improves without it.\n",
    "\n",
    "C5.0 is Quinlan’s latest version release under a proprietary license. It uses less memory and builds smaller rulesets than C4.5 while being more accurate.\n",
    "\n",
    "CART (Classification and Regression Trees) is very similar to C4.5, but it differs in that it supports numerical target variables (regression) and does not compute rule sets. CART constructs binary trees using the feature and threshold that yield the largest information gain at each node.\n",
    "\n",
    "**scikit-learn uses an optimised version of the CART algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   [1] [L. Breiman, and A. Cutler, \"Random Forests\"](http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "276px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
